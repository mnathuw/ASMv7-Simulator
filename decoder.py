# convert the binary string to a decimal integer
def Decoder(binary_str):
    decimal = int(binary_str, 2)
    return decimal
# print(Decoder('00000000000000000000000000001010'))  # example usage, should print 10